# Train GPT2

This is a fully functional training recipe of GPT-2 with model, training, eval, and data loading code. 

Replicated hyperparameters from the GPT-2 and -3 papers. 

Trained the model with fineweb-edu dataset 10B version on HuggingFace.
